demo()
m <- matrix (nrow = 2, ncol = 3)
m
m <- matrix (1:6, nrow = 2, ncol = 3)
m
m1 <- 1:10
dim(m1) >- c(2,5)
dim(m1) <- c(2,5)
install.packages("ggplot2")
library("ggplot2", lib.loc="C:/Users/Fafner/Documents/R/win-library/3.0")
require(ggplot2)
require(plyr)
require(dplyr)
require(pls) # PLS
require(glmnet) # LASSO & elastic net
require(caret) # Feature selection. http://cran.r-project.org/web/packages/caret/vignettes/caret.pdf
require(corrplot)
require(elasticnet)
require(neuralnet)
# Définition du répertoire de travail
setwd("~/R/MSIAAP/Data_analysis")
### Lecture des données ###
# Lecture des fichiers, regroupés en un fichier commun dat
dat <- do.call(cbind, lapply(list.files("~/R/MSIAAP/Data_analysis/Data",
full.names = TRUE), read.delim, header = TRUE))
dat <- dat[,!(names(dat) %in% "Ligand")] # enlève les colonnes "Ligands" qui étaient répétées
# NB : grep() = pattern matching and replacement
dim(dat) # 279 variables : 278 descripteurs moléculaires + 1 variable explicative
# Sélection des variables non numériques
dat[!sapply(dat,is.numeric)]  # Aucune n'est retenue, les variables ont toutes été bien reconnues
str(dat)
na <- is.na(dat[[ncol(dat)]])
as.numeric(na)
dataset <- dat
dataset$Vss <- log(dataset$Vss)
names(dataset)[names(dataset)=="Vss"] <- "logvss" # renomme Vss en logvss
fit <- plsr(logvss ~ ., data=dataset, validation="CV")
summary(fit)
# make predictions
predictions <- predict(fit, dataset, ncomp=6)
# summarize accuracy
rmse <- mean((longley$Employed - predictions)^2)
rmse <- mean((dataset$logvss - predictions)^2)
print(rmse)
res.plsr <- plsr(logvss ~ ., data = dataset, validation = "CV", segments = 2)
res.plsr$validation$PRESS
fit$validation$PRESS
min(res.plsr$validation$PRESS)
min(fit$validation$PRESS)
x <- as.matrix(dataset[,1:278])
y <- as.matrix(longley[,279])
y <- as.matrix(dataset[,279])
# fit model
fit <- glmnet(x, y, family="gaussian", alpha=0.5, lambda=0.001)
# summarize the fit
summary(fit)
# make predictions
predictions <- predict(fit, x, type="link")
# summarize accuracy
rmse <- mean((y - predictions)^2)
print(rmse)
fit
plot(fit)
y <- dataset[,279]
fit <- glmnet(x, y, family="gaussian", alpha=0.5, lambda=0.001)
fit
plot(fit)
fit <- glmnet(x, y)
plot(fit)
print(fit)
coef(fit)
print(fit)
fit <- glmnet(x, y, family="gaussian", alpha=0.5, lambda=0.001)
print(fit)
coef(fit,s=0.1)
fit <- glmnet(x, y)
coef(fit,s=0.1)
cvfit <- cv.glmnet(x, y)
plot(cv.fit)
plot(cvfit)
View(dataset)
names(dataset)
res.pls <- plsr(logvss ~ ., data=dataset, validation="CV")
res.pls
summary(res.pls)
fit <- glmnet(x, y, family="gaussian", alpha=0.5, lambda=0.001)
print(fit)
fit <- glmnet(x, y, family="gaussian", alpha=0.5, lambda= "lambda.min")
fit <- glmnet(x, y, family="gaussian", alpha=0.5, lambda= 0.0001)
print(fit)
?seq()
lambda <- 10^((-2):2) # Séquences de puissances de 10 à tester pour C
lambda
y[-ID]
ID <- sample(1:nrow(dataset), round((nrow(dataset))/2))
y[-ID]
lambda <- 10^((-5):1) # Séquences de puissances de 10 à tester pour lambda
alpha <- seq(from = 0, to = 1, by = 0.1)
enrmoyen = NULL
for (i in lambda)
{
for (k in alpha)
{
pred.CV <- matrix(NA, nrow = 633, ncol = 30)
pbc <- rep(NA, 30)
for (j in 1:30)
{
ID <- sample(1:nrow(dataset), round((nrow(dataset))/2))
fit <- glmnet(x[-ID,], y[-ID], family="gaussian", alpha=alpha, lambda= lambda)
pred.glm <- predict(fit, newdata = x[ID, ])
pred.CV[ID, j] <- pred.glm # on a construit le modèle sans ID, donc on prédit ID
fit <- glmnet(x[ID,], y[ID], family="gaussian", alpha=alpha, lambda= lambda)
pred.glm <- predict(fit, newdata = x[-ID, ])
pred.CV[- ID, j] <- pred.glm
rmse[j] <- mean((y - pred.CV[, j])^2) #pourcentage de prédiction pour chaque modèle
}
enrmoyen <- c(enrmoyen, mean(rmse)) # Evolution du pourcentage de prédiction selon C
}
}
lambda <- 10^((-5):1) # Séquences de puissances de 10 à tester pour lambda
alpha <- seq(from = 0, to = 1, by = 0.1)
enrmoyen = NULL
for (i in lambda)
{
for (k in alpha)
{
pred.CV <- matrix(NA, nrow = 633, ncol = 30)
pbc <- rep(NA, 30)
for (j in 1:30)
{
ID <- sample(1:nrow(dataset), round((nrow(dataset))/2))
fit <- glmnet(x[-ID,], y[-ID], family="gaussian", alpha=alpha, lambda= lambda)
pred.glm <- predict(fit, newdata = x[ID, ])
pred.CV[ID, j] <- pred.glm # on a construit le modèle sans ID, donc on prédit ID
fit <- glmnet(x[ID,], y[ID], family="gaussian", alpha=alpha, lambda= lambda)
pred.glm <- predict(fit, newdata = x[-ID, ])
pred.CV[- ID, j] <- pred.glm
rmse[j] <- mean((y - pred.CV[, j])^2) #pourcentage de prédiction pour chaque modèle
}
enrmoyen <- c(enrmoyen, mean(rmse)) # Evolution du pourcentage de prédiction selon C
}
}
lambda <- 10^((-5):1) # Séquences de puissances de 10 à tester pour lambda
alpha <- seq(from = 0, to = 1, by = 0.1)
enrmoyen = NULL
for (i in lambda)
{
for (k in alpha)
{
pred.CV <- matrix(NA, nrow = 633, ncol = 30)
pbc <- rep(NA, 30)
for (j in 1:30)
{
ID <- sample(1:nrow(dataset), round((nrow(dataset))/2))
fit <- glmnet(x[-ID,], y[-ID], family="gaussian", alpha=alpha, lambda= lambda)
pred.glm <- predict(fit, newdata = x[ID, ])
pred.CV[ID, j] <- pred.glm # on a construit le modèle sans ID, donc on prédit ID
fit <- glmnet(x[ID,], y[ID], family="gaussian", alpha=alpha, lambda= lambda)
pred.glm <- predict(fit, newdata = x[-ID, ])
pred.CV[- ID, j] <- pred.glm
rmse[j] <- mean((y - pred.CV[, j])^2) #pourcentage de prédiction pour chaque modèle
}
enrmoyen <- c(enrmoyen, mean(rmse)) # Evolution du pourcentage de prédiction selon C
}
}
lambda <- 10^((-5):1) # Séquences de puissances de 10 à tester pour lambda
alpha <- seq(from = 0, to = 1, by = 0.1)
enrmoyen = NULL
for (i in lambda)
{
for (k in alpha)
{
pred.CV <- matrix(NA, nrow = 633, ncol = 30)
rmse <- rep(NA, 30)
for (j in 1:30)
{
ID <- sample(1:nrow(dataset), round((nrow(dataset))/2))
fit <- glmnet(x[-ID,], y[-ID], family="gaussian", alpha=alpha, lambda= lambda)
pred.glm <- predict(fit, x[ID, ])
pred.CV[ID, j] <- pred.glm # on a construit le modèle sans ID, donc on prédit ID
fit <- glmnet(x[ID,], y[ID], family="gaussian", alpha=alpha, lambda= lambda)
pred.glm <- predict(fit, x[-ID, ])
pred.CV[- ID, j] <- pred.glm
rmse[j] <- mean((y - pred.CV[, j])^2) #pourcentage de prédiction pour chaque modèle
}
enrmoyen <- c(enrmoyen, mean(rmse)) # Evolution du pourcentage de prédiction selon C
}
}
ID <- sample(1:nrow(dataset), round((nrow(dataset))/2))
fit <- glmnet(x[-ID,], y[-ID], family="gaussian", alpha=alpha, lambda= lambda)
fit <- glmnet(x, y, family="gaussian", alpha=0.5, lambda= 0.001)
fit <- glmnet(x[-ID,], y[-ID], family="gaussian", alpha=0.5, lambda= 0.001)
pred.glm <- predict(fit, x[ID, ])
pred.glm
